{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c499f566-d8c4-41f1-b12b-0c6cdd08335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src import parse_salary_row, extract_skills, soft_skills, TECHNICAL_SKILL_ALIASES, title_pattern, desc_pattern, exclude_pattern, build_alias_lookup, build_skill_regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cb3da-9446-49b5-9c0b-49478f0f2a9f",
   "metadata": {},
   "source": [
    "## Load in datasets (from multiple sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5092856-342a-4a0d-b751-d62985272394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/lukebarousse/data-analyst-job-postings-google-search\n",
    "# taken from google search\n",
    "df = pd.read_csv(\"../data/gsearch_jobs.csv\")\n",
    "\n",
    "# https://www.kaggle.com/datasets/rashikrahmanpritom/data-science-job-posting-on-glassdoor?select=Cleaned_DS_Jobs.csv\n",
    "# all from glassdoor\n",
    "df2 = pd.read_csv(\"../data/Cleaned_DS_Jobs_2020.csv\")\n",
    "\n",
    "# https://www.kaggle.com/datasets/elahehgolrokh/data-science-job-postings-with-salaries-2025\n",
    "#df2 = pd.read_csv(\"data_science_job_posts_2025.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5621036-cba8-4e1e-a23b-5f199dbb2a9f",
   "metadata": {},
   "source": [
    "### First dataframe cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2b62f-7786-454e-9213-a82141c2e2f0",
   "metadata": {},
   "source": [
    "let's take this dataframe and extract entry-level/new-grad positions using key words found in either the job title or the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32eb9ae2-b8b5-4feb-bb6f-786e899afafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query out non entry level jobs through text matching\n",
    "df[\"is_entry_level\"] = (\n",
    "    df[\"title\"].str.lower().str.contains(title_pattern, regex=True, na=False)\n",
    "    |\n",
    "    df[\"description\"].str.lower().str.contains(desc_pattern, regex=True, na=False)\n",
    ")\n",
    "\n",
    "df[\"is_entry_level\"] = df[\"is_entry_level\"] & (\n",
    "    ~df[\"title\"].str.lower().str.contains(exclude_pattern, regex=True, na=False)\n",
    ")\n",
    "\n",
    "entry_jobs = df[df[\"is_entry_level\"]].drop(\"is_entry_level\",axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979f7ad9-bbde-49b0-a845-b0fa3e1291c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the year\n",
    "entry_jobs[\"date_time\"] = pd.to_datetime(df[\"date_time\"])\n",
    "entry_jobs[\"year\"] = entry_jobs[\"date_time\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a8d5b6-3490-4a04-8f8d-0cd80350fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns we will be keeping\n",
    "col_keep = ['title', \"year\",\"via\",\"salary_pay\",\"salary_rate\",\"description\",\"description_tokens\",\"location\",\"work_from_home\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9f59ae-ce2c-4634-b504-c390d981b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Temp\\ipykernel_13276\\2168505758.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  entry_jobs_cleaned['work_from_home'] = entry_jobs_cleaned['work_from_home'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "entry_jobs_cleaned = entry_jobs[col_keep].copy()\n",
    "\n",
    "# via column = source of job post\n",
    "# change NaN values to be False\n",
    "entry_jobs_cleaned['via'] = entry_jobs_cleaned['via'].str.strip('via ')\n",
    "entry_jobs_cleaned['work_from_home'] = entry_jobs_cleaned['work_from_home'].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197edcc6-c5dc-4282-b6e6-9863b87adaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning salary, works for both hourly, monthly, and yearly salary text\n",
    "entry_jobs_cleaned[[\"salary_min_annual\", \"salary_max_annual\", \"salary_type\"]] = df.apply(\n",
    "    lambda r: parse_salary_row(r[\"salary_pay\"], r[\"salary_rate\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abad02f8-9e8a-4686-aac2-4ddb68f6498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_cleaned = entry_jobs_cleaned.drop([\"salary_pay\",\"salary_rate\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541f7e65-10e7-43d5-bcf7-5aa70c663b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>location</th>\n",
       "      <th>work_from_home</th>\n",
       "      <th>salary_min_annual</th>\n",
       "      <th>salary_max_annual</th>\n",
       "      <th>salary_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>2023</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Job Title: Entry Level Business Analyst / Prod...</td>\n",
       "      <td>[]</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>143000.0</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - Consumer Goods - Contract to Hire</td>\n",
       "      <td>2023</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Enthusiastic Data Analyst for processing sales...</td>\n",
       "      <td>['powerpoint', 'excel', 'power_bi']</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Warehouse and Data Analyst</td>\n",
       "      <td>2023</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>Be part of a team that unleashes the power of ...</td>\n",
       "      <td>['sql']</td>\n",
       "      <td>Kansas City, KS</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Research/Data Analyst-CES - Now Hiring</td>\n",
       "      <td>2023</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>Why you'll love working for this Department:\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Jefferson City, MO</td>\n",
       "      <td>False</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>hourly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst, Strategy</td>\n",
       "      <td>2023</td>\n",
       "      <td>Jobs Trabajo.org</td>\n",
       "      <td>Everything we do at Sunrun is driven by a dete...</td>\n",
       "      <td>['tableau', 'snowflake', 'sql', 'python']</td>\n",
       "      <td>Jefferson City, MO</td>\n",
       "      <td>False</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  year               via  \\\n",
       "0                                      Data Analyst  2023          LinkedIn   \n",
       "1  Data Analyst - Consumer Goods - Contract to Hire  2023            Upwork   \n",
       "2                   Data Warehouse and Data Analyst  2023          LinkedIn   \n",
       "3  Associate Research/Data Analyst-CES - Now Hiring  2023          Snagajob   \n",
       "4                            Data Analyst, Strategy  2023  Jobs Trabajo.org   \n",
       "\n",
       "                                         description  \\\n",
       "0  Job Title: Entry Level Business Analyst / Prod...   \n",
       "1  Enthusiastic Data Analyst for processing sales...   \n",
       "2  Be part of a team that unleashes the power of ...   \n",
       "3  Why you'll love working for this Department:\\n...   \n",
       "4  Everything we do at Sunrun is driven by a dete...   \n",
       "\n",
       "                          description_tokens                 location  \\\n",
       "0                                         []         United States      \n",
       "1        ['powerpoint', 'excel', 'power_bi']                Anywhere    \n",
       "2                                    ['sql']       Kansas City, KS      \n",
       "3                                         []    Jefferson City, MO      \n",
       "4  ['tableau', 'snowflake', 'sql', 'python']    Jefferson City, MO      \n",
       "\n",
       "   work_from_home  salary_min_annual  salary_max_annual salary_type  \n",
       "0           False           101000.0           143000.0      annual  \n",
       "1            True                NaN                NaN         NaN  \n",
       "2           False                NaN                NaN         NaN  \n",
       "3           False            31200.0            52000.0      hourly  \n",
       "4           False            90000.0           110000.0      annual  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a62d93-ac48-40b4-b784-0f1498906ab6",
   "metadata": {},
   "source": [
    "Let's now extract skills from the description (both technical and soft). We already have a column \"description_tokens\" provided for us but let's see if we can get something more comprehensive before we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91a74a5-afc9-4d88-addc-df45fa4745e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just checking what skills they included. Could be useful to add to my running list\n",
    "# entry_cleaned.description_tokens\n",
    "# unique_skills = entry_cleaned.description_tokens.apply(lambda x: x[1:-1].split(','))\n",
    "# skills = set(\n",
    "#     skill\n",
    "#     for sublist in unique_skills\n",
    "#     for skill in sublist\n",
    "# )\n",
    "\n",
    "# skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9c520e-dc03-4950-9b6d-830ba804036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_lookup = build_alias_lookup(TECHNICAL_SKILL_ALIASES)\n",
    "skill_pattern = build_skill_regex(TECHNICAL_SKILL_ALIASES)\n",
    "\n",
    "tech_skills = entry_cleaned[\"description\"].apply(\n",
    "    lambda txt: extract_skills(txt, alias_lookup, skill_pattern)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38db2cbb-44d9-4a16-aec9-9aed91e4407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aws',\n",
       " 'redshift',\n",
       " 'sagemaker',\n",
       " 'python',\n",
       " 'scala',\n",
       " 'r',\n",
       " 'spark',\n",
       " 'sql',\n",
       " 'pandas',\n",
       " 'numpy']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_skills.iloc[4710]#.iloc[5:20].loc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69cf8694-5b56-4385-b9e4-64700bb3ac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['pandas', 'redshift', 'aws', 'python', 'numpy', 'spark', 'sql', 'scala']\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_cleaned.description_tokens.iloc[4710]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e111b75-f44b-4b78-919a-847e252c0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "entry_cleaned[\"description_tokens\"] = entry_cleaned[\"description_tokens\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c3650e1-9930-4913-8eef-6b922272b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      []\n",
       "1                           [powerpoint, excel, power_bi]\n",
       "2                                                   [sql]\n",
       "3                                                      []\n",
       "4                       [tableau, snowflake, sql, python]\n",
       "                              ...                        \n",
       "4709                  [power_bi, tableau, sql, r, python]\n",
       "4710    [pandas, redshift, aws, python, numpy, spark, ...\n",
       "4711                                                [sql]\n",
       "4712                                                [sql]\n",
       "4713                                                [sql]\n",
       "Name: description_tokens, Length: 4714, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_cleaned[\"description_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31eec239-dd8c-4fd9-b7b8-a4fe0332f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tech_skill_counts = Counter(\n",
    "    skill\n",
    "    for lst in tech_skills\n",
    "    for skill in lst\n",
    ")\n",
    "\n",
    "token_skill_counts = Counter(\n",
    "    skill\n",
    "    for lst in entry_cleaned[\"description_tokens\"].dropna()\n",
    "    for skill in lst\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ea0e226-7fcd-4bac-a57d-b7ba3bea6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_skills.to_csv('our_cleaned.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb736bf7-f961-4b86-9881-da6634a829fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sql': 2096,\n",
       "         'excel': 1876,\n",
       "         'python': 1516,\n",
       "         'tableau': 1426,\n",
       "         'power bi': 1325,\n",
       "         'r': 972,\n",
       "         'word': 360,\n",
       "         'powerpoint': 352,\n",
       "         'java': 309,\n",
       "         'go': 265,\n",
       "         'aws': 210,\n",
       "         'javascript': 178,\n",
       "         'azure': 172,\n",
       "         'snowflake': 159,\n",
       "         'spss': 137,\n",
       "         'outlook': 134,\n",
       "         'databricks': 117,\n",
       "         'sharepoint': 110,\n",
       "         'visual basic': 104,\n",
       "         'docker': 99,\n",
       "         'looker': 97,\n",
       "         'spark': 95,\n",
       "         'pyspark': 84,\n",
       "         'tensorflow': 79,\n",
       "         'pandas': 72,\n",
       "         'mysql': 71,\n",
       "         'nosql': 69,\n",
       "         'scala': 65,\n",
       "         'git': 64,\n",
       "         'bigquery': 63,\n",
       "         'redshift': 63,\n",
       "         'hadoop': 61,\n",
       "         'postgres': 58,\n",
       "         'cognos': 58,\n",
       "         'qlik': 57,\n",
       "         'jira': 54,\n",
       "         'numpy': 53,\n",
       "         'airflow': 53,\n",
       "         'linux': 51,\n",
       "         'visio': 47,\n",
       "         'gcp': 45,\n",
       "         'shell': 43,\n",
       "         'perl': 42,\n",
       "         'matplotlib': 41,\n",
       "         'scikit-learn': 40,\n",
       "         'kubernetes': 38,\n",
       "         'pytorch': 37,\n",
       "         'unix': 34,\n",
       "         'php': 26,\n",
       "         'microstrategy': 26,\n",
       "         'keras': 19,\n",
       "         'sagemaker': 19,\n",
       "         'terminal': 17,\n",
       "         'bash': 15,\n",
       "         'mongodb': 14,\n",
       "         'typescript': 13,\n",
       "         'seaborn': 12,\n",
       "         'gitlab': 12,\n",
       "         'mssql': 10,\n",
       "         'swift': 9,\n",
       "         'splunk': 8,\n",
       "         'rshiny': 8,\n",
       "         'powershell': 8,\n",
       "         'ruby': 8,\n",
       "         'bitbucket': 4,\n",
       "         'selenium': 4,\n",
       "         'julia': 3,\n",
       "         'atlassian': 3,\n",
       "         'dart': 3,\n",
       "         'aurora': 2,\n",
       "         'redis': 1})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_skill_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2526de6-8fe0-4ea5-bf9d-1e815bc356ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sql': 2048,\n",
       "         'excel': 1792,\n",
       "         'python': 1489,\n",
       "         'tableau': 1402,\n",
       "         'power_bi': 1357,\n",
       "         'r': 853,\n",
       "         'word': 348,\n",
       "         'powerpoint': 342,\n",
       "         'sas': 332,\n",
       "         'java': 305,\n",
       "         'c': 241,\n",
       "         'spreadsheet': 206,\n",
       "         'aws': 203,\n",
       "         'go': 201,\n",
       "         'azure': 162,\n",
       "         'javascript': 160,\n",
       "         'snowflake': 157,\n",
       "         'c++': 144,\n",
       "         'alteryx': 143,\n",
       "         'sap': 138,\n",
       "         'spss': 136,\n",
       "         'outlook': 131,\n",
       "         'sharepoint': 105,\n",
       "         'docker': 99,\n",
       "         'looker': 94,\n",
       "         'spark': 90,\n",
       "         'pyspark': 82,\n",
       "         'vba': 80,\n",
       "         'tensorflow': 74,\n",
       "         'pandas': 72,\n",
       "         'ssis': 69,\n",
       "         'mysql': 68,\n",
       "         'bigquery': 63,\n",
       "         'redshift': 63,\n",
       "         'scala': 62,\n",
       "         'hadoop': 60,\n",
       "         'git': 60,\n",
       "         'github': 59,\n",
       "         'cognos': 58,\n",
       "         'dax': 56,\n",
       "         'jira': 54,\n",
       "         'nosql': 54,\n",
       "         'numpy': 52,\n",
       "         'airflow': 52,\n",
       "         'qlik': 51,\n",
       "         'visio': 47,\n",
       "         'matlab': 46,\n",
       "         'linux': 43,\n",
       "         'pl/sql': 42,\n",
       "         'perl': 42,\n",
       "         'shell': 41,\n",
       "         'gcp': 41,\n",
       "         'matplotlib': 40,\n",
       "         'scikit-learn': 38,\n",
       "         'postgresql': 35,\n",
       "         'ssrs': 33,\n",
       "         'pytorch': 32,\n",
       "         'html': 27,\n",
       "         't-sql': 27,\n",
       "         'postgres': 25,\n",
       "         'microstrategy': 25,\n",
       "         'unix': 23,\n",
       "         'php': 22,\n",
       "         'crystal': 20,\n",
       "         'assembly': 20,\n",
       "         'keras': 19,\n",
       "         'terminal': 17,\n",
       "         'jupyter': 16,\n",
       "         'visual_basic': 15,\n",
       "         'plotly': 15,\n",
       "         'mongodb': 13,\n",
       "         'typescript': 13,\n",
       "         'bash': 12,\n",
       "         'gitlab': 12,\n",
       "         'seaborn': 11,\n",
       "         'mssql': 10,\n",
       "         'swift': 9,\n",
       "         'css': 8,\n",
       "         'splunk': 8,\n",
       "         'rshiny': 8,\n",
       "         'unix/linux': 8,\n",
       "         'gdpr': 8,\n",
       "         'powershell': 7,\n",
       "         'ruby': 6,\n",
       "         'jquery': 5,\n",
       "         'datarobot': 5,\n",
       "         'bitbucket': 4,\n",
       "         'no-sql': 4,\n",
       "         'selenium': 4,\n",
       "         'node.js': 3,\n",
       "         'julia': 3,\n",
       "         'linux/unix': 3,\n",
       "         'atlassian': 3,\n",
       "         'dart': 3,\n",
       "         'c/c++': 2,\n",
       "         'fortran': 2,\n",
       "         'aurora': 2,\n",
       "         'asp.net': 2,\n",
       "         'mongo': 2,\n",
       "         'redis': 1,\n",
       "         'nltk': 1,\n",
       "         'rust': 1,\n",
       "         'cobol': 1,\n",
       "         'groovy': 1,\n",
       "         'node': 1,\n",
       "         'twilio': 1,\n",
       "         'vb.net': 1,\n",
       "         'powerpoints': 1})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_skill_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "386cea89-c3f6-4d14-bf3f-8b51f6ed19f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excel', 'sas', 'spss', 'spreadsheet']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_cleaned.description_tokens.iloc[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6cd9d40f-ca40-41cc-872d-f8cb80ddd47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLD: ['excel', 'sas', 'spss', 'spreadsheet']\n",
      "NEW: ['excel', 'spss']\n"
     ]
    }
   ],
   "source": [
    "i = 14\n",
    "\n",
    "print(\"OLD:\", entry_cleaned.loc[i, \"description_tokens\"])\n",
    "print(\"NEW:\", tech_skills.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1508a703-5d78-46ff-8a48-6fc8fddcf34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A pioneer in K-12 education since 2000, Amplify is leading the way in next-generation curriculum and assessment. Our core and supplemental programs in ELA, math, and science engage all students in rigorous learning and inspire them to think deeply, creatively, and for themselves. Our formative assessment products help teachers identify the targeted instruction students need to build a strong... foundation in early reading and math. All of our programs provide educators with powerful tools that help them understand and respond to the needs of every student. Today, Amplify serves more than 10 million students in all 50 states. For more information, visitamplify.com.\\n\\nAmplify seeks a hard-working individual to join our organization as an Associate Data Analyst. To do well in this role, you need an excellent eye for detail, experience as a data technician, and a deep understanding of popular data analysis tools and databases. Amplify offers many opportunities for professional growth to broaden knowledge and have exposure to new tools and skills.\\n\\nAmplify\\'s COVID-19 vaccination policy requires all staff to provide proof of vaccination for in-person meetings unless an approved exemption is provided.\\n\\nResponsibilities of the Associate Data Analyst:\\n• Filter and \"clean\" data by reviewing reports, dashboards, and performance indicators to locate and correct problems\\n• Work with management to prioritize business and information needs\\n• Locate and define new process improvement opportunities\\n• Translate business needs into data requirements, identify gaps, and implement appropriate solutions.\\n• Track and communicate project status, issues, risks, and decisions to management in an Agile, change-laden environment\\n• Proficiency in statistics, analysis, and research methods\\n• Assists with improving existing reporting systems\\n• Performs complex analysis of large datasets to determine quality issues and offer solutions for updates\\n\\nRequired Qualifications of the Associate Data Analyst:\\n• Bachelor\\'s degree in business administration, economics, computer science, management information systems, or related field or equivalent related experience\\n• Technical knowledge regarding data models, database design development, data mining, and segmentation techniques\\n• Strong understanding of and experience with reporting and working with databases\\n• Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS, etc.)\\n• Strong analytical skills with the ability to collect, organize, research, and disseminate significant amounts of information with attention to detail and accuracy\\n• Deep expertise with technologies and tools such as:\\n• Google Sheets (auto-populate dynamically from multiple data sources, develop advanced formulates, Google App Scripts for spreadsheet automation)\\n• Gsuite\\n• Excel (use of advanced formulas and functions)\\n• Proficient in building reports and understanding how sorting and grouping affect the resulting answer\\n• Process-oriented with excellent documentation skills\\n\\nPreferred Qualifications of the Associate Data Analyst:\\n• Experience with one or more of the following SaaS platforms: Salesforce, Netsuite, or Workday\\n• Experience working with Agile Methodologies\\n• Experience working in the education technology field\\n• Minimum of 2 years of experience in data-related roles or applicable internship program\\n• Certification in a related process (PMP, Lean Sigma Six, Agile Scrum-master) is a plus\\n\\nWhat we offer:\\n\\nSalary is only one component of the Amplify Total Rewards package, which includes a lucrative 401(k) plan, incentive stock options, competitive health insurance and mental health options, basic life insurance, paid time off, parental leave, and access to best-in-class development programs. The gross salary range for this role is $50,000 - $60,000.\\n\\nWe celebratediversityand are committed to creating an inclusive environment for all employees. To that end, we seek to recruit, develop and retain the most talented people from adiversecandidate pool.\\n\\nAmplify is an Equal Opportunity Employer of Minorities, Females, Protected Veterans and Individuals with Disabilities.\\n\\nThis position may be funded, in whole or in part, through American Recovery & Reinvestment Act funds.\\n\\nAmplify Education, Inc. is an E-Verify participant'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_cleaned.description.iloc[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca454388-b36b-48c0-92d3-4a1f11134984",
   "metadata": {},
   "source": [
    "________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb77ee-a29e-4a34-b19b-dd9fa257cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[\"is_entry_level\"] = (\n",
    "#     df2[\"Job Title\"].str.lower().str.contains(title_pattern, regex=True, na=False)\n",
    "#     |\n",
    "#     df2[\"Job Description\"].str.lower().str.contains(desc_pattern, regex=True, na=False)\n",
    "# )\n",
    "\n",
    "# df2[\"is_entry_level\"] = df2[\"is_entry_level\"] & (\n",
    "#     ~df2[\"Job Title\"].str.lower().str.contains(exclude_pattern, regex=True, na=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc0dcf-b93b-4396-ae12-f99888d9a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entry_jobs2 = df2[df2[\"is_entry_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339472a-108a-461d-bf4f-ec8e31dbaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entry_jobs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a6149-216b-4445-b4ad-245bef07e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test[[\"salary_min_annual\", \"salary_max_annual\", \"salary_type\"]] = df.apply(\n",
    "#     lambda r: parse_salary_row(r[\"salary_pay\"], r[\"salary_rate\"]),\n",
    "#     axis=1\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
